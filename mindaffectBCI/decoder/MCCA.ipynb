{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiway CCA\n",
    "This notebook contains testing code for multi-way CCA based learning using a parafac tensor decomposition in the algorithm core, rather than a SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindaffectBCI.decoder.offline.datasets import get_dataset\n",
    "from mindaffectBCI.decoder.model_fitting import MultiCCA\n",
    "from mindaffectBCI.decoder.decodingCurveSupervised import decodingCurveSupervised\n",
    "from mindaffectBCI.decoder.utils import block_permute\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from mindaffectBCI.decoder.analyse_datasets import analyse_dataset, analyse_datasets, debug_test_dataset, debug_test_single_dataset\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['figure.figsize'] = [12, 8] # bigger default figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example data\n",
    "dataset_loader, files, dataroot = get_dataset('plos_one', regexp='s3')\n",
    "evttypes=('re','fe')\n",
    "tau_ms = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level threshold - single outputs with multiple levels\n",
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/khash\",regexp='vep_threshold')\n",
    "evttypes='hot-on'\n",
    "tau_ms = 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual - acuity - multiple outputs at the same time.\n",
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/mark\",regexp='vep_threshold_scale')\n",
    "evttypes='hot-on'\n",
    "tau_ms = 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual - acuity - multiple outputs at the same time.\n",
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/mark\",regexp='visual_acuity')\n",
    "evttypes='output2event'\n",
    "tau_ms = 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "savefile = files[-1]\n",
    "X,Y,coords = dataset_loader(savefile)\n",
    "oY  = Y.copy()\n",
    "oX  = X.copy()\n",
    "fs=coords[1]['fs']\n",
    "ch_names=coords[-1]['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset specific pre-processing..\n",
    "if 'visual_acuity' in savefile: # strip the calibration trials as they have a different meaning for objID==1\n",
    "    print('Stripping first 10 trials')\n",
    "    X = oX[10:,...] \n",
    "    Y = oY[10:,...,1:]\n",
    "elif 'threshold' in savefile:\n",
    "    print('Stripping first 10 trials')\n",
    "    X = oX[10:,...] \n",
    "    Y = oY[10:,...,1:]\n",
    "    print(\"Adding virtual outputs\")\n",
    "    # add virtual outputs so always at least 30 outputs so we can test the decoding performance\n",
    "    Y = np.concatenate((Y, block_permute(Y, -30, axis=-1)), -1) # (..., nY)\n",
    "    Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output is: X=eeg, Y=stimulus, coords=meta-info about dimensions of X and Y\n",
    "print(\"EEG: X({}){} @{}Hz\".format([c['name'] for c in coords],X.shape,coords[1]['fs']))                            \n",
    "print(\"STIMULUS: Y({}){}\".format([c['name'] for c in coords[:-1]]+['output'],Y.shape))\n",
    "plt.imshow(X[0,:,:].T,aspect='auto');plt.xlabel('time (samp)');plt.title('X');plt.show()\n",
    "plt.imshow(Y[0,:,:].T,aspect='auto');plt.xlabel('time (samp)');plt.title('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the true-label and convert to brain-response\n",
    "from stim2event import stim2event\n",
    "# map to event sequence, for rising/falling edges\n",
    "try:\n",
    "    Ye,evtlabs = stim2event(Y,evtypes=evttypes,axis=-2) # (tr,samp,nY,e)\n",
    "except:\n",
    "    Ye = stim2event(Y,evtypes=evttypes,axis=-2) # (tr,samp,nY,e)\n",
    "    evtlabs= np.arange(Ye.shape[-1])\n",
    "print(\"Evtlabs: {}\".format(evtlabs))\n",
    "# extract the true target to fit to, using horible slicing trick\n",
    "Ye_true = Ye[..., 0:1, :] #  (tr,samp,1,e)\n",
    "print(\"X={}\".format(X.shape))\n",
    "print(\"Y_true={}\".format(Ye_true.shape))\n",
    "plt.imshow(Ye_true[0,:,0,:].T,aspect='auto',origin='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary statistics\n",
    "from updateSummaryStatistics import updateSummaryStatistics, plot_summary_statistics\n",
    "tau = tau_ms * fs // 1000 # ms->samples\n",
    "Cxx, Cxy, Cyy = updateSummaryStatistics(X, Ye_true, tau=tau)\n",
    "print(\"Cxx={}\".format(Cxx.shape))\n",
    "print(\"Cxy={}\".format(Cxy.shape))\n",
    "print(\"Cyy={}\".format(Cyy.shape))\n",
    "plot_summary_statistics(Cxx, Cxy, Cyy, evtlabs=evtlabs, fs=fs, ch_names=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Cyy.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto',origin='normal');plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from multipleCCA import multipleCCA, robust_whitener\n",
    "from updateSummaryStatistics import plot_factoredmodel\n",
    "# run and plot the normal CCA model\n",
    "J, W, R = multipleCCA(Cxx, Cxy, Cyy, reg=.02, rank=rank)\n",
    "plot_factoredmodel(W, R, ch_names=ch_names, fs=fs, evtlabs=evtlabs);plt.show()\n",
    "# eval this models performance\n",
    "from scoreStimulus import scoreStimulus\n",
    "Fe = scoreStimulus(X, W, R)\n",
    "from scoreOutput import scoreOutput\n",
    "Fy = scoreOutput(Fe, Ye, R=R, dedup0=True) # (nM,nTrl,nEp,nY)\n",
    "from decodingCurveSupervised import decodingCurveSupervised, plot_decoding_curve\n",
    "dc=decodingCurveSupervised(Fy)\n",
    "plot_decoding_curve(*dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try with the tensor factored version.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. X spatial whitener\n",
    "from multipleCCA import robust_whitener\n",
    "Wx, iWx = robust_whitener(Cxx,reg=.02)\n",
    "\n",
    "wCxxw = np.einsum(\"de,df,eg\",Cxx,Wx,Wx)\n",
    "plt.imshow(wCxxw,aspect='auto');plt.title('Whitened: Cxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Cyy combined whitener..\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Wy, iWy = robust_whitener(Cyy.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),reg=.02) # (e*tau,e*tau)\n",
    "Wy = Wy.reshape(Cyy.shape[1:]) # (e,tau,e,tau)\n",
    "iWy = iWy.reshape(Cyy.shape[1:]) # (e,tau,e,tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Y temporal whitener\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Cyy_tau = np.sum(Cyy,axis=(0,1,3))\n",
    "#plt.imshow(Cyy_tau,aspect='auto');plt.title('Cyy_tau');plt.colorbar();plt.show()\n",
    "Wy_tau, iWy_tau = robust_whitener(Cyy_tau,reg=.0)\n",
    "\n",
    "#wtauCyy_tauwtau = np.einsum(\"tu,tv,uw\",Cyy_tau,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyy_tauwtau,aspect='auto');plt.title('Whitended: Cyy_tau');plt.colorbar();plt.show()\n",
    "\n",
    "#wtauCyywtau = np.einsum(\"metfu,tv,uw->mevfw\",Cyy,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyywtau.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto');plt.title('Tau Whitened: Cyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Y event whitener\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Cyy_e = np.sum(Cyy,axis=(0,2,4))\n",
    "Wy_e, iWy_e = robust_whitener(Cyy_e,reg=.02)\n",
    "\n",
    "#weCyy_ewe = np.einsum(\"ed,ef,dg\",Cyy_e,Wy_e,Wy_e)\n",
    "#plt.imshow(weCyy_ewe,aspect='auto');plt.title('Whitended: Cyy_tau');plt.show()\n",
    "\n",
    "#wtauCyywtau = np.einsum(\"metfu,tv,uw->mevfw\",Cyy,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyywtau.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto');plt.title('Tau Whitened: Cyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCxy(Cxy, evtlabs=None, fs=None):\n",
    "    times = np.arange(Cxy.shape[-2])\n",
    "    if fs is not None: times = times/fs\n",
    "    fit,ax = plt.subplots(nrows=1,ncols=Cxy.shape[1],sharey='row')\n",
    "    for ei in range(Cxy.shape[1]):\n",
    "        plt.sca(ax[ei])\n",
    "        plt.imshow(Cxy[0,ei,:,:],aspect='auto',extent=[times[0],times[-1],0,Cxy.shape[-1]])\n",
    "        if evtlabs is not None: plt.title(evtlabs[ei])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the spatial whiteners\n",
    "WxCxy = np.einsum(\"metd,df->metf\",Cxy,Wx)\n",
    "plotCxy(WxCxy,evtlabs,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set factored/nonfactored\n",
    "isFactored = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total-temporal-whitener\n",
    "if not isFactored:\n",
    "    WxCxyWy_t = np.einsum(\"metd,etgu->mgud\",WxCxy,Wy)\n",
    "\n",
    "    print(\"WxCxyWy {}\".format(WxCxyWy_t.shape))\n",
    "    plotCxy(WxCxyWy_t,evtlabs,fs); plt.suptitle(\"Combined Temporal Whitened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factored-whitener\n",
    "if isFactored:\n",
    "    WxCxyWy_f = np.einsum(\"metd,eg,tu->mgud\",WxCxy,Wy_e,Wy_tau)\n",
    "\n",
    "    print(\"WxCxyWy {}\".format(WxCxyWy_f.shape))\n",
    "    plotCxy(WxCxyWy_f,evtlabs,fs); plt.suptitle(\"Factored Temporal Whitened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD/PARAFAC decomp\n",
    "from tensorly.decomposition import parafac\n",
    "if isFactored: \n",
    "    ten = WxCxyWy_f[0,...]\n",
    "else:\n",
    "    ten = WxCxyWy_t[0,...]\n",
    "print(\"ten={}\".format(ten.shape))\n",
    "normW = np.sum(np.abs(ten.ravel()))\n",
    "plotCxy(ten[np.newaxis,...],evtlabs,fs); plt.colorbar();plt.suptitle(\"Tensor: {}\".format(normW)); plt.show()\n",
    "kruskal_decomp = parafac(ten, rank=4, normalize_factors=False)#True)\n",
    "weight = kruskal_decomp[0]\n",
    "factors = kruskal_decomp[1]\n",
    "print(\"Decomp={},{},{}\".format(*[f.shape for f in factors]))\n",
    "We = factors[0]\n",
    "Wt = factors[1]\n",
    "Wd = factors[2]\n",
    "print(\"w={}\".format(weight))\n",
    "\n",
    "# check the reconstruction error\n",
    "from tensorly import kruskal_to_tensor\n",
    "recons = kruskal_to_tensor(kruskal_decomp)\n",
    "normRecons = np.sum(np.abs(recons.ravel()))\n",
    "print('recons={}'.format(recons.shape))\n",
    "plotCxy(recons[np.newaxis,...],evtlabs,fs); plt.colorbar(); plt.suptitle(\"Reconstruction: {}\".format(normRecons)); plt.show()\n",
    "err = np.sum(np.abs(ten.ravel()-recons.ravel()))\n",
    "print('|W|={} |parafac|={}'.format(normW,normRecons,err))\n",
    "\n",
    "plotCxy((ten-recons)[np.newaxis,...],evtlabs,fs); plt.colorbar(); plt.suptitle(\"Error: {}\".format(err)); plt.show()\n",
    "print('|err|={}'.format(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the decomp: e,t,d x rank\n",
    "ch_names = np.arange(Wd.shape[0]) if ch_names is None else ch_names\n",
    "times = np.arange(Wt.shape[0])/fs\n",
    "evts = evtlabs\n",
    "fig, axes = plt.subplots(nrows=We.shape[1],ncols=3,sharex='col',sharey=True)\n",
    "if axes.ndim<2: axes=axes[np.newaxis,:]\n",
    "for r in range(We.shape[1]):\n",
    "    sgn = np.sign(We[:,r].flat[abs(We[:,r]).argmax()]) # normalize size of the event weighting\n",
    "    wght = weight[r]*np.sqrt(np.sum(Wd[:,r]**2))*np.sqrt(np.sum(Wt[:,r]**2))*np.sqrt(np.sum(We[:,r]**2))\n",
    "    plt.sca(axes[r,0]); plt.plot(ch_names, Wd[:,r]/np.sqrt(np.sum(Wd[:,r]**2))); plt.grid();  plt.ylabel('#{}\\n{:3.2f}'.format(r,wght))\n",
    "    if r==0: plt.title('Space');\n",
    "    elif r==We.shape[1]-1: plt.xlabel('ch')\n",
    "    plt.sca(axes[r,1]); plt.plot(times,    sgn*Wt[:,r]/np.sqrt(np.sum(Wt[:,r]**2))); plt.grid(); \n",
    "    if r==0: plt.title('Time') \n",
    "    elif r==We.shape[1]-1: plt.xlabel('time (s)')\n",
    "    plt.sca(axes[r,2]); plt.plot(evts,     sgn*We[:,r]/np.sqrt(np.sum(We[:,r]**2))); plt.grid(); \n",
    "    if r==0: plt.title('Event')\n",
    "    elif r==We.shape[1]-1: plt.xlabel('intensity') \n",
    "plt.suptitle(\"{} evttypes={}\".format(files[-1][-30:],evttypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make equivalent to the multiCCA outputs (so can re-use apply methods)\n",
    "W = Wd.T # (rank,d)\n",
    "R = np.einsum(\"tk,ek->ket\",Wt,We) # (rank,e,tau)\n",
    "plot_factoredmodel(W, R, ch_names=ch_names, fs=fs, evtlabs=evtlabs);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the spatial whitener\n",
    "W = W @ iWx # (d,rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the temporal whitener\n",
    "if isFactored:\n",
    "    R = np.einsum(\"ket,ef,tu->kfu\",R,iWy_e,iWy_tau)\n",
    "else:\n",
    "    R = np.einsum(\"ket,etfu->kfu\",R,iWy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to the data\n",
    "from scoreStimulus import scoreStimulus\n",
    "Fe = scoreStimulus(X, W, R)\n",
    "from scoreOutput import scoreOutput\n",
    "Fy = scoreOutput(Fe, Ye, R=R, dedup0=True) # (nM,nTrl,nEp,nY)\n",
    "from decodingCurveSupervised import decodingCurveSupervised, plot_decoding_curve\n",
    "dc=decodingCurveSupervised(Fy)\n",
    "plot_decoding_curve(*dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
