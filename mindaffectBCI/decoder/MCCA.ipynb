{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiway CCA\n",
    "This notebook contains testing code for multi-way CCA based learning using a parafac tensor decomposition in the algorithm core, rather than a SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindaffectBCI.decoder.offline.datasets import get_dataset\n",
    "from mindaffectBCI.decoder.model_fitting import MultiCCA\n",
    "from mindaffectBCI.decoder.decodingCurveSupervised import decodingCurveSupervised\n",
    "from mindaffectBCI.decoder.utils import block_permute\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from mindaffectBCI.decoder.analyse_datasets import analyse_dataset, analyse_datasets, debug_test_dataset, debug_test_single_dataset\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['figure.figsize'] = [12, 8] # bigger default figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example data\n",
    "dataset_loader, files, dataroot = get_dataset('plos_one', regexp='s3')\n",
    "evttypes=('re','fe')\n",
    "tau_ms = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/mark\",regexp='vep_threshold_.*1539')\n",
    "evttypes='hot-on'\n",
    "tau_ms = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load S3 -- high perf subject\n",
    "X,oY,coords = dataset_loader(files[-1])\n",
    "fs=coords[1]['fs']\n",
    "ch_names=coords[-1]['coords']\n",
    "# output is: X=eeg, Y=stimulus, coords=meta-info about dimensions of X and Y\n",
    "print(\"EEG: X({}){} @{}Hz\".format([c['name'] for c in coords],X.shape,coords[1]['fs']))                            \n",
    "print(\"STIMULUS: Y({}){}\".format([c['name'] for c in coords[:-1]]+['output'],oY.shape))\n",
    "plt.imshow(X[0,:,:],aspect='auto');plt.title('X');plt.show()\n",
    "plt.imshow(oY[0,:,:],aspect='auto');plt.title('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add virtual outputs so always at least 30 outputs so we can test the decoding performance\n",
    "ooY  = oY.copy()\n",
    "oY = np.concatenate((oY, block_permute(oY, -30, axis=-1)), -1) # (..., nY)\n",
    "oY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the true-label and convert to brain-response\n",
    "from stim2event import stim2event\n",
    "# map to event sequence, for rising/falling edges\n",
    "Y,evtlabs = stim2event(oY,evtypes=evttypes,axis=-2) # (tr,samp,nY,e)\n",
    "print(\"Evtlabs: {}\".format(evtlabs))\n",
    "# extract the true target to fit to, using horible slicing trick\n",
    "Y_true = Y[..., 0:1, :] #  (tr,samp,1,e)\n",
    "print(\"Y_true={}\".format(Y_true.shape))\n",
    "plt.imshow(Y_true[0,:,0,:].T,aspect='auto',origin='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary statistics\n",
    "from updateSummaryStatistics import updateSummaryStatistics, plot_summary_statistics\n",
    "tau = tau_ms * fs // 1000 # ms->samples\n",
    "Cxx, Cxy, Cyy = updateSummaryStatistics(X, Y_true, tau=tau)\n",
    "print(\"Cxx={}\".format(Cxx.shape))\n",
    "print(\"Cxy={}\".format(Cxy.shape))\n",
    "print(\"Cyy={}\".format(Cyy.shape))\n",
    "plot_summary_statistics(Cxx, Cxy, Cyy, evtlabs=evtlabs, fs=fs, ch_names=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Cyy.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto',origin='normal');plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from multipleCCA import multipleCCA, robust_whitener\n",
    "from updateSummaryStatistics import plot_factoredmodel\n",
    "# run and plot the normal CCA model\n",
    "J, W, R = multipleCCA(Cxx, Cxy, Cyy, reg=.02, rank=rank)\n",
    "plot_factoredmodel(W, R, ch_names=ch_names, fs=fs, evtlabs=evtlabs);plt.show()\n",
    "# eval this models performance\n",
    "from scoreStimulus import scoreStimulus\n",
    "Fe = scoreStimulus(X, W, R)\n",
    "from scoreOutput import scoreOutput\n",
    "Fy = scoreOutput(Fe, Y, R=R, dedup0=True) # (nM,nTrl,nEp,nY)\n",
    "from decodingCurveSupervised import decodingCurveSupervised, plot_decoding_curve\n",
    "dc=decodingCurveSupervised(Fy)\n",
    "plot_decoding_curve(*dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try with the tensor factored version.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. X spatial whitener\n",
    "from multipleCCA import robust_whitener\n",
    "Wx, iWx = robust_whitener(Cxx,reg=.02)\n",
    "\n",
    "wCxxw = np.einsum(\"de,df,eg\",Cxx,Wx,Wx)\n",
    "plt.imshow(wCxxw,aspect='auto');plt.title('Whitened: Cxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Cyy combined whitener..\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Wy, iWy = robust_whitener(Cyy.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),reg=.02) # (e*tau,e*tau)\n",
    "Wy = Wy.reshape(Cyy.shape[1:]) # (e,tau,e,tau)\n",
    "iWy = iWy.reshape(Cyy.shape[1:]) # (e,tau,e,tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Y temporal whitener\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Cyy_tau = np.sum(Cyy,axis=(0,1,3))\n",
    "#plt.imshow(Cyy_tau,aspect='auto');plt.title('Cyy_tau');plt.colorbar();plt.show()\n",
    "Wy_tau, iWy_tau = robust_whitener(Cyy_tau,reg=.0)\n",
    "\n",
    "#wtauCyy_tauwtau = np.einsum(\"tu,tv,uw\",Cyy_tau,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyy_tauwtau,aspect='auto');plt.title('Whitended: Cyy_tau');plt.colorbar();plt.show()\n",
    "\n",
    "#wtauCyywtau = np.einsum(\"metfu,tv,uw->mevfw\",Cyy,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyywtau.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto');plt.title('Tau Whitened: Cyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Y event whitener\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Cyy_e = np.sum(Cyy,axis=(0,2,4))\n",
    "Wy_e, iWy_e = robust_whitener(Cyy_e,reg=.02)\n",
    "\n",
    "#weCyy_ewe = np.einsum(\"ed,ef,dg\",Cyy_e,Wy_e,Wy_e)\n",
    "#plt.imshow(weCyy_ewe,aspect='auto');plt.title('Whitended: Cyy_tau');plt.show()\n",
    "\n",
    "#wtauCyywtau = np.einsum(\"metfu,tv,uw->mevfw\",Cyy,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyywtau.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto');plt.title('Tau Whitened: Cyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCxy(Cxy):\n",
    "    for ei in range(Cxy.shape[1]):\n",
    "        plt.subplot(1,Cxy.shape[1],ei+1)\n",
    "        plt.imshow(Cxy[0,ei,:,:],aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the spatial whiteners\n",
    "WxCxy = np.einsum(\"metd,df->metf\",Cxy,Wx)\n",
    "plotCxy(WxCxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set factored/nonfactored\n",
    "isFactored = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total-temporal-whitener\n",
    "if not isFactored:\n",
    "    WxCxyWy_t = np.einsum(\"metd,etgu->mgud\",WxCxy,Wy)\n",
    "\n",
    "    print(\"WxCxyWy {}\".format(WxCxyWy_t.shape))\n",
    "    plotCxy(WxCxyWy_t); plt.suptitle(\"Combined Temporal Whitener\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factored-whitener\n",
    "if isFactored:\n",
    "    WxCxyWy_f = np.einsum(\"metd,eg,tu->mgud\",WxCxy,Wy_e,Wy_tau)\n",
    "\n",
    "    print(\"WxCxyWy {}\".format(WxCxyWy_f.shape))\n",
    "    plotCxy(WxCxyWy_f); plt.suptitle(\"Factored Temporal Whitener\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD/PARAFAC decomp\n",
    "from tensorly.decomposition import parafac\n",
    "if isFactored: \n",
    "    ten = WxCxyWy_f[0,...]\n",
    "else:\n",
    "    ten = WxCxyWy_t[0,...]\n",
    "print(\"ten={}\".format(ten.shape))\n",
    "normW = np.sum(np.abs(ten.ravel()))\n",
    "plotCxy(ten[np.newaxis,...]); plt.colorbar();plt.suptitle(\"Tensor: {}\".format(normW)); plt.show()\n",
    "kruskal_decomp = parafac(ten, rank=2, normalize_factors=True)\n",
    "weight = kruskal_decomp[0]\n",
    "factors = kruskal_decomp[1]\n",
    "print(\"Decomp={},{},{}\".format(*[f.shape for f in factors]))\n",
    "We = factors[0]\n",
    "Wt = factors[1]\n",
    "Wd = factors[2]\n",
    "print(\"w={}\".format(weight))\n",
    "\n",
    "# check the reconstruction error\n",
    "from tensorly import kruskal_to_tensor\n",
    "recons = kruskal_to_tensor(kruskal_decomp)\n",
    "normRecons = np.sum(np.abs(recons.ravel()))\n",
    "print('recons={}'.format(recons.shape))\n",
    "plotCxy(recons[np.newaxis,...]); plt.colorbar(); plt.suptitle(\"Reconstruction: {}\".format(normRecons)); plt.show()\n",
    "err = np.sum(np.abs(ten.ravel()-recons.ravel()))\n",
    "print('|W|={} |parafac|={}'.format(normW,normRecons,err))\n",
    "\n",
    "plotCxy((ten-recons)[np.newaxis,...]); plt.colorbar(); plt.suptitle(\"Error: {}\".format(err)); plt.show()\n",
    "print('|err|={}'.format(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the decomp: e,t,d x rank\n",
    "ch_names = np.arange(Wd.shape[0]) if ch_names is None else ch_names\n",
    "times = np.arange(Wt.shape[0])/fs\n",
    "evts = evtlabs\n",
    "fig, axes = plt.subplots(nrows=We.shape[1],ncols=3,sharex='col',sharey=True)\n",
    "for r in range(We.shape[1]):\n",
    "    plt.sca(axes[r,0]); plt.plot(ch_names, Wd[:,r]*weight[r]); plt.grid(); \n",
    "    if r==0: plt.title('Space');\n",
    "    elif r==We.shape[1]-1: plt.xlabel('ch')\n",
    "    plt.sca(axes[r,1]); plt.plot(times,    Wt[:,r]*weight[r]); plt.grid(); \n",
    "    if r==0: plt.title('Time') \n",
    "    elif r==We.shape[1]-1: plt.xlabel('time (s)')\n",
    "    plt.sca(axes[r,2]); plt.plot(evts,     We[:,r]*weight[r]); plt.grid(); \n",
    "    if r==0: plt.title('Event')\n",
    "    elif r==We.shape[1]-1: plt.xlabel('intensity') \n",
    "plt.suptitle(\"{} evttypes={}\".format(files[-1][-30:],evttypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make equivalent to the multiCCA outputs (so can re-use apply methods)\n",
    "W = Wd.T # (rank,d)\n",
    "R = np.einsum(\"tk,ek->ket\",Wt,We) # (rank,e,tau)\n",
    "plot_factoredmodel(W, R, ch_names=ch_names, fs=fs, evtlabs=evtlabs);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the spatial whitener\n",
    "W = W @ iWx # (d,rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the temporal whitener\n",
    "if isFactored:\n",
    "    R = np.einsum(\"ket,ef,tu->kfu\",R,iWy_e,iWy_tau)\n",
    "else:\n",
    "    R = np.einsum(\"ket,etfu->kfu\",R,iWy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to the data\n",
    "from scoreStimulus import scoreStimulus\n",
    "Fe = scoreStimulus(X, W, R)\n",
    "from scoreOutput import scoreOutput\n",
    "Fy = scoreOutput(Fe, Y, R=R, dedup0=True) # (nM,nTrl,nEp,nY)\n",
    "from decodingCurveSupervised import decodingCurveSupervised, plot_decoding_curve\n",
    "dc=decodingCurveSupervised(Fy)\n",
    "plot_decoding_curve(*dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
