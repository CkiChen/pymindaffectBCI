{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiway CCA\n",
    "This notebook contains testing code for multi-way CCA based learning using a parafac tensor decomposition in the algorithm core, rather than a SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindaffectBCI.decoder.offline.datasets import get_dataset\n",
    "import mindaffectBCI.decoder.offline.load_mindaffectBCI \n",
    "from mindaffectBCI.decoder.model_fitting import MultiCCA\n",
    "from mindaffectBCI.decoder.decodingCurveSupervised import decodingCurveSupervised\n",
    "from mindaffectBCI.decoder.utils import block_permute\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from mindaffectBCI.decoder.analyse_datasets import analyse_dataset, analyse_datasets, debug_test_dataset, debug_test_single_dataset\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['figure.figsize'] = [12, 8] # bigger default figures\n",
    "savefile=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCxy(Cxy, evtlabs=None, fs=None):\n",
    "    times = np.arange(Cxy.shape[-2])\n",
    "    if fs is not None: times = times/fs\n",
    "    fit,ax = plt.subplots(nrows=1,ncols=Cxy.shape[1],sharey='row')\n",
    "    for ei in range(Cxy.shape[1]):\n",
    "        plt.sca(ax[ei])\n",
    "        plt.imshow(Cxy[0,ei,:,:],aspect='auto',extent=[times[0],times[-1],0,Cxy.shape[-1]])\n",
    "        if evtlabs is not None: plt.title(evtlabs[ei])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data -- from dataset\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example data\n",
    "dataset_loader, files, dataroot = get_dataset('plos_one', regexp='s3')\n",
    "savefile = files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level threshold - single outputs with multiple levels\n",
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/khash\",regexp='vep_threshold')\n",
    "savefile = files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual - acuity - multiple outputs at the same time.\n",
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/mark\",regexp='vep_threshold_scale')\n",
    "savefile = files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual - acuity - multiple outputs at the same time.\n",
    "dataset_loader, files, dataroot = get_dataset('mindaffectBCI',exptdir=\"~/Desktop/mark\",regexp='visual_acuity')\n",
    "savefile = files[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data -- ask user\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savefile is None:\n",
    "    %gui tk\n",
    "    from tkinter import Tk\n",
    "    from tkinter.filedialog import askopenfilename\n",
    "    import os\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    savefile = askopenfilename(initialdir=os.getcwd(),\n",
    "                                title='Chose mindaffectBCI save File',\n",
    "                                filetypes=(('mindaffectBCI','mindaffectBCI*.txt'),('All','*.*')))\n",
    "    dataset_loader = mindaffectBCI.decoder.offline.load_mindaffectBCI.load_mindaffectBCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the type of events to use and response length parameters based on the experiment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args=dict(stopband=((45,65),(3,25,'bandpass')),out_fs=100)\n",
    "tau_ms=550\n",
    "offset_ms=100\n",
    "evtypes=('re','fe')\n",
    "\n",
    "# dataset specific pre-processing args\n",
    "if 'threshold' in savefile:\n",
    "    # model a different response for each level\n",
    "    evttypes='hot-on'\n",
    "    tau_ms = 550\n",
    "    \n",
    "elif 'visual_acuity' in savefile:\n",
    "    # model a different response for each output = each cell in the stimulus matrix\n",
    "    evttypes='output2event'\n",
    "    tau_ms = 550\n",
    "    \n",
    "elif 'face_detection' in savefile:\n",
    "    # model different response for each level\n",
    "    evttypes=('>0','>4','>6','>8')\n",
    "    tau_ms = 350\n",
    "    offset_ms = 0\n",
    "    dataset_args=dict(stopband=((45,65),(2,15,'bandpass')))\n",
    "\n",
    "else:\n",
    "    # model re/fe responses only for the cued target stimulus\n",
    "    evtypes=('re','fe')\n",
    "    tau_ms = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "X,Y,coords = dataset_loader(savefile, *dataset_args)\n",
    "oY  = Y.copy()\n",
    "oX  = X.copy()\n",
    "fs=coords[1]['fs']\n",
    "ch_names=coords[-1]['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset specific pre-processing..\n",
    "if 'visual_acuity' in savefile: # strip the calibration trials as they have a different meaning for objID==1\n",
    "    print('Stripping first 10 trials')\n",
    "    X = oX[10:,...] \n",
    "    Y = oY[10:,...,1:]\n",
    "elif 'threshold' in savefile:\n",
    "    print('Stripping first 10 trials')\n",
    "    X = oX[10:,...] \n",
    "    Y = oY[10:,...,1:]\n",
    "    print(\"Adding virtual outputs\")\n",
    "    # add virtual outputs so always at least 30 outputs so we can test the decoding performance\n",
    "    Y = np.concatenate((Y, block_permute(Y, -30, axis=-1)), -1) # (..., nY)\n",
    "    Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output is: X=eeg, Y=stimulus, coords=meta-info about dimensions of X and Y\n",
    "print(\"EEG: X({}){} @{}Hz\".format([c['name'] for c in coords],X.shape,coords[1]['fs']))                            \n",
    "print(\"STIMULUS: Y({}){}\".format([c['name'] for c in coords[:-1]]+['output'],Y.shape))\n",
    "plt.imshow(X[0,:,:].T,aspect='auto');plt.xlabel('time (samp)');plt.title('X');plt.show()\n",
    "plt.imshow(Y[0,:,:].T,aspect='auto');plt.xlabel('time (samp)');plt.title('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the true-label and convert to brain-response\n",
    "from stim2event import stim2event\n",
    "# map to event sequence, for rising/falling edges\n",
    "try:\n",
    "    Ye,evtlabs = stim2event(Y,evtypes=evttypes,axis=-2) # (tr,samp,nY,e)\n",
    "except:\n",
    "    Ye = stim2event(Y,evtypes=evttypes,axis=-2) # (tr,samp,nY,e)\n",
    "    evtlabs= np.arange(Ye.shape[-1])\n",
    "print(\"Evtlabs: {}\".format(evtlabs))\n",
    "# extract the true target to fit to, using horible slicing trick\n",
    "Ye_true = Ye[..., 0:1, :] #  (tr,samp,1,e)\n",
    "print(\"X={}\".format(X.shape))\n",
    "print(\"Y_true={}\".format(Ye_true.shape))\n",
    "plt.imshow(Ye_true[0,:,0,:].T,aspect='auto',origin='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the summary statistics\n",
    "from updateSummaryStatistics import updateSummaryStatistics, plot_summary_statistics, plot_erp\n",
    "tau = int(tau_ms * fs // 1000) # ms->samples\n",
    "offset = int(offset_ms * fs // 1000) # ms->samples\n",
    "print('tau = {}   offset={}'.format(tau,offset))\n",
    "Cxx, Cxy, Cyy = updateSummaryStatistics(X, Ye_true, tau=tau, offset=offset)\n",
    "print(\"Cxx={}\".format(Cxx.shape))\n",
    "print(\"Cxy={}\".format(Cxy.shape))\n",
    "print(\"Cyy={}\".format(Cyy.shape))\n",
    "plot_summary_statistics(Cxx, Cxy, Cyy, evtlabs=evtlabs, fs=fs, ch_names=ch_names)\n",
    "plt.show(block=False)\n",
    "print(np.diag(Cyy[0,:,0,:,0]))\n",
    "plot_erp(Cxy/np.diag(Cyy[0,:,0,:,0])[:,np.newaxis,np.newaxis],fs=fs,evtlabs=evtlabs,ch_names=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Cyy.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto',origin='normal');plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from multipleCCA import multipleCCA, robust_whitener\n",
    "from updateSummaryStatistics import plot_factoredmodel\n",
    "# run and plot the normal CCA model\n",
    "J, W, R = multipleCCA(Cxx, Cxy, Cyy, reg=.02, rank=rank)\n",
    "plot_factoredmodel(W, R, ch_names=ch_names, fs=fs, evtlabs=evtlabs);plt.show()\n",
    "# eval this models performance\n",
    "from scoreStimulus import scoreStimulus\n",
    "Fe = scoreStimulus(X, W, R)\n",
    "from scoreOutput import scoreOutput\n",
    "Fy = scoreOutput(Fe, Ye, R=R, dedup0=True) # (nM,nTrl,nEp,nY)\n",
    "from decodingCurveSupervised import decodingCurveSupervised, plot_decoding_curve\n",
    "dc=decodingCurveSupervised(Fy, nvirt_out=-30)\n",
    "plot_decoding_curve(*dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try with the tensor factored version.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. X spatial whitener\n",
    "from multipleCCA import robust_whitener\n",
    "Wx, iWx = robust_whitener(Cxx,reg=.02)\n",
    "\n",
    "wCxxw = np.einsum(\"de,df,eg\",Cxx,Wx,Wx)\n",
    "plt.imshow(wCxxw,aspect='auto');plt.title('Whitened: Cxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Cyy combined whitener..\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Wy, iWy = robust_whitener(Cyy.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),reg=.02) # (e*tau,e*tau)\n",
    "Wy = Wy.reshape(Cyy.shape[1:]) # (e,tau,e,tau)\n",
    "iWy = iWy.reshape(Cyy.shape[1:]) # (e,tau,e,tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Y temporal whitener\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Cyy_tau = np.sum(Cyy,axis=(0,1,3))\n",
    "#plt.imshow(Cyy_tau,aspect='auto');plt.title('Cyy_tau');plt.colorbar();plt.show()\n",
    "Wy_tau, iWy_tau = robust_whitener(Cyy_tau,reg=.0)\n",
    "\n",
    "#wtauCyy_tauwtau = np.einsum(\"tu,tv,uw\",Cyy_tau,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyy_tauwtau,aspect='auto');plt.title('Whitended: Cyy_tau');plt.colorbar();plt.show()\n",
    "\n",
    "#wtauCyywtau = np.einsum(\"metfu,tv,uw->mevfw\",Cyy,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyywtau.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto');plt.title('Tau Whitened: Cyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Y event whitener\n",
    "#  Cyy = (nM,e,tau,e,tau)\n",
    "Cyy_e = np.sum(Cyy,axis=(0,2,4))\n",
    "Wy_e, iWy_e = robust_whitener(Cyy_e,reg=.02)\n",
    "\n",
    "#weCyy_ewe = np.einsum(\"ed,ef,dg\",Cyy_e,Wy_e,Wy_e)\n",
    "#plt.imshow(weCyy_ewe,aspect='auto');plt.title('Whitended: Cyy_tau');plt.show()\n",
    "\n",
    "#wtauCyywtau = np.einsum(\"metfu,tv,uw->mevfw\",Cyy,Wy_tau,Wy_tau)\n",
    "#plt.imshow(wtauCyywtau.reshape((Cyy.shape[1]*Cyy.shape[2],-1)),aspect='auto');plt.title('Tau Whitened: Cyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the spatial whiteners\n",
    "WxCxy = np.einsum(\"metd,df->metf\",Cxy,Wx)\n",
    "plotCxy(WxCxy,evtlabs,fs)\n",
    "plt.show(block=False)\n",
    "plot_erp(WxCxy/np.diag(Cyy[0,:,0,:,0])[:,np.newaxis,np.newaxis],evtlabs=evtlabs,fs=fs,ch_names=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set factored/nonfactored\n",
    "isFactored = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total-temporal-whitener\n",
    "if not isFactored:\n",
    "    WxCxyWy_t = np.einsum(\"metd,etgu->mgud\",WxCxy,Wy)\n",
    "\n",
    "    print(\"WxCxyWy {}\".format(WxCxyWy_t.shape))\n",
    "    plotCxy(WxCxyWy_t,evtlabs,fs); plt.suptitle(\"Combined Temporal Whitened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factored-whitener\n",
    "if isFactored:\n",
    "    WxCxyWy_f = np.einsum(\"metd,eg,tu->mgud\",WxCxy,Wy_e,Wy_tau)\n",
    "\n",
    "    print(\"WxCxyWy {}\".format(WxCxyWy_f.shape))\n",
    "    plotCxy(WxCxyWy_f,evtlabs,fs); plt.suptitle(\"Factored Temporal Whitened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD/PARAFAC decomp\n",
    "from tensorly.decomposition import parafac\n",
    "if isFactored: \n",
    "    ten = WxCxyWy_f[0,...]\n",
    "else:\n",
    "    ten = WxCxyWy_t[0,...]\n",
    "print(\"ten={}\".format(ten.shape))\n",
    "normW = np.sum(np.abs(ten.ravel()))\n",
    "plotCxy(ten[np.newaxis,...],evtlabs,fs); plt.colorbar();plt.suptitle(\"Tensor: {}\".format(normW)); plt.show()\n",
    "kruskal_decomp = parafac(ten, rank=2, normalize_factors=False)#True)\n",
    "weight = kruskal_decomp[0]\n",
    "factors = kruskal_decomp[1]\n",
    "print(\"Decomp={},{},{}\".format(*[f.shape for f in factors]))\n",
    "We = factors[0]\n",
    "Wt = factors[1]\n",
    "Wd = factors[2]\n",
    "print(\"w={}\".format(weight))\n",
    "\n",
    "# check the reconstruction error\n",
    "from tensorly import kruskal_to_tensor\n",
    "recons = kruskal_to_tensor(kruskal_decomp)\n",
    "normRecons = np.sum(np.abs(recons.ravel()))\n",
    "print('recons={}'.format(recons.shape))\n",
    "plotCxy(recons[np.newaxis,...],evtlabs,fs); plt.colorbar(); plt.suptitle(\"Reconstruction: {}\".format(normRecons)); plt.show()\n",
    "err = np.sum(np.abs(ten.ravel()-recons.ravel()))\n",
    "print('|W|={} |parafac|={}'.format(normW,normRecons,err))\n",
    "\n",
    "plotCxy((ten-recons)[np.newaxis,...],evtlabs,fs); plt.colorbar(); plt.suptitle(\"Error: {}\".format(err)); plt.show()\n",
    "print('|err|={}'.format(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the decomp: e,t,d x rank\n",
    "ch_names = np.arange(Wd.shape[0]) if ch_names is None else ch_names\n",
    "times = np.arange(Wt.shape[0])/fs\n",
    "evts = evtlabs\n",
    "fig, axes = plt.subplots(nrows=We.shape[1],ncols=3,sharex='col',sharey=True)\n",
    "if axes.ndim<2: axes=axes[np.newaxis,:]\n",
    "for r in range(We.shape[1]):\n",
    "    Wer = We[:,r]; nWer = np.sqrt(np.sum(Wer**2))\n",
    "    Wdr = Wd[:,r]; nWdr = np.sqrt(np.sum(Wdr**2))\n",
    "    Wtr = Wt[:,r]; nWtr = np.sqrt(np.sum(Wtr**2))\n",
    "    sgn = np.sign(Wer.flat[abs(Wer).argmax()]) # normalize size of the event weighting\n",
    "    wght = weight[r]*nWer*nWdr*nWtr\n",
    "    plt.sca(axes[r,0]); plt.plot(ch_names, Wdr/nWdr); plt.grid();  plt.ylabel('#{}\\n{:3.2f}'.format(r,wght))\n",
    "    if r==0: plt.title('Space');\n",
    "    elif r==We.shape[1]-1: plt.xlabel('ch')\n",
    "    plt.sca(axes[r,1]); plt.plot(times,    sgn*Wtr/nWtr); plt.grid(); \n",
    "    if r==0: plt.title('Time') \n",
    "    elif r==We.shape[1]-1: plt.xlabel('time (s)')\n",
    "    plt.sca(axes[r,2]); plt.plot(evts,     sgn*Wer/nWer); plt.grid(); \n",
    "    if r==0: plt.title('Event')\n",
    "    elif r==We.shape[1]-1: plt.xlabel('intensity') \n",
    "plt.suptitle(\"{} evttypes={}\".format(savefile[-30:],evttypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make equivalent to the multiCCA outputs (so can re-use apply methods)\n",
    "W = Wd.T # (rank,d)\n",
    "R = np.einsum(\"tk,ek->ket\",Wt,We) # (rank,e,tau)\n",
    "plot_factoredmodel(W, R, ch_names=ch_names, fs=fs, evtlabs=evtlabs);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the spatial whitener\n",
    "W = W @ iWx # (d,rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the temporal whitener\n",
    "if isFactored:\n",
    "    R = np.einsum(\"ket,ef,tu->kfu\",R,iWy_e,iWy_tau)\n",
    "else:\n",
    "    R = np.einsum(\"ket,etfu->kfu\",R,iWy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to the data\n",
    "from scoreStimulus import scoreStimulus\n",
    "Fe = scoreStimulus(X, W, R)\n",
    "from scoreOutput import scoreOutput\n",
    "Fy = scoreOutput(Fe, Ye, R=R, dedup0=True) # (nM,nTrl,nEp,nY)\n",
    "from decodingCurveSupervised import decodingCurveSupervised, plot_decoding_curve\n",
    "dc=decodingCurveSupervised(Fy)\n",
    "plot_decoding_curve(*dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_matrix_variate_gaussian(X:np.ndarray,axis=(-2,-1),rcond=1e-12):\n",
    "    cov = [ np.eye(X.shape[i],X.shape[i]) for i in axis]\n",
    "    icov = [ np.eye(X.shape[i],X.shape[i]) for i in axis]\n",
    "\n",
    "    # build the index expressions\n",
    "    sumidx = [ chr(ord('a')+i) for i in range(X.ndim)] # unique char idx \n",
    "    lsub = sumidx.copy();    rsub = sumidx.copy() \n",
    "    lsub[axis[0]]='u';       rsub[axis[0]]='v'\n",
    "    lsub[axis[1]]='w';       rsub[axis[1]]='x'\n",
    "    idxstr = [\"{},{},{}\".format(\"\".join(lsub),'uv',\"\".join(rsub)),\n",
    "              \"{},{},{}\".format(\"\".join(lsub),'wx',\"\".join(rsub))]\n",
    "    print('idxstrs={}'.format(idxstr))\n",
    "    for iter in range(40):\n",
    "        # axis[0]\n",
    "        icov[0] = np.linalg.pinv(cov[0],rcond=rcond,hermitian=True)\n",
    "        cov[1] = np.einsum(idxstr[0], X, icov[0], X)/X.shape[axis[0]]\n",
    "        # axis[1]\n",
    "        icov[1] = np.linalg.pinv(cov[1],rcond=rcond,hermitian=True)\n",
    "        cov[0] = np.einsum(idxstr[1], X, icov[1], X)/X.shape[axis[1]]\n",
    "        # balance norm over components\n",
    "        norm = [ np.mean(np.diag(c)) for c in cov ]\n",
    "        nf = np.sqrt(np.prod(norm))\n",
    "        for i in range(len(cov)):\n",
    "            cov[i] = cov[i] * nf / norm[i]\n",
    "        # TODO[]: convergence testing   \n",
    "    return cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nL=5; nR=9\n",
    "L = np.random.standard_normal((1000,nL))@np.random.standard_normal((nL,nL))\n",
    "R = np.random.standard_normal((1000,nR))@np.random.standard_normal((nR,nR))\n",
    "X = np.einsum(\"il,ir->ilr\",L,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covfull = X.reshape((X.shape[0],-1)).T@X.reshape((X.shape[0],-1))\n",
    "print(\"Full\\n{}\".format(covfull))\n",
    "print('{}'.format(np.diag(covfull)))\n",
    "plt.imshow(covfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = est_matrix_variate_gaussian(X)\n",
    "for i,c in enumerate(cov):\n",
    "    print(\"{})\\n {}\".format(i,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = np.kron(cov[0],cov[1])\n",
    "print('Decomp\\n{}'.format(decomp))\n",
    "print(\"{}\".format(np.diag(decomp)))\n",
    "plt.imshow(decomp);plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(covfull-decomp)/covfull\n",
    "plt.imshow(covfull-decomp);plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [ robust_whitener(c)[0] for c in cov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xw = np.einsum(\"ilr,lm,rs->ims\",X,W[0],W[1])\n",
    "covfullw = Xw.reshape((Xw.shape[0],-1)).T@Xw.reshape((Xw.shape[0],-1))\n",
    "print(\"Full\\n{}\".format(covfullw))\n",
    "print('{}'.format(np.diag(covfullw)))\n",
    "plt.imshow(covfullw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
